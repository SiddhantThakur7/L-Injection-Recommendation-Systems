{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from subprocess import call\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from scipy import stats\n",
    "\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise import SVDpp, NMF\n",
    "from surprise.prediction_algorithms.knns import KNNBasic, KNNWithMeans, KNNWithZScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.read_csv(\"u.data\", sep=\"\\t\", names = ['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "rating\n",
    "rating_matrix1 = rating.pivot_table(index = ['user_id'], columns = ['item_id'], values = ['rating'])\n",
    "rating_matrix1\n",
    "\n",
    "\n",
    "rating_matrix = rating_matrix1.dropna(thresh = 10, axis = 1)\n",
    "rating_matrix = rating_matrix.fillna(0)\n",
    "Ratings = np.array(rating_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1152)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Create_Training_set(arr):\n",
    "    test = arr\n",
    "    users = []\n",
    "    items = []\n",
    "    stars = []\n",
    "    for i in range(arr.shape[0]):\n",
    "        a = np.where(test[i] > 0)[0]\n",
    "        stars.extend(np.take(test[i], a))\n",
    "        items.extend([k+1 for k in list(a)])\n",
    "        U = [i+1]*len(a)\n",
    "        users.extend(U)\n",
    "\n",
    "    star_dict= {'userID':users,\n",
    "                'itemsID':items,\n",
    "                'ratings':stars\n",
    "                }\n",
    "    Ratings_for_Svd=pd.DataFrame(star_dict)\n",
    "    return Ratings_for_Svd\n",
    "\n",
    "def Create_test_Set(arr):\n",
    "    test = arr\n",
    "    users = []\n",
    "    items = []\n",
    "    stars = []\n",
    "    for i in range(arr.shape[0]):\n",
    "        a = np.where(test[i] == 0)[0]\n",
    "        stars.extend(np.take(test[i], a))\n",
    "        items.extend([k+1 for k in list(a)])\n",
    "        U = [i+1]*len(a)\n",
    "        users.extend(U)\n",
    "\n",
    "\n",
    "    star_dict= {'userID':users,\n",
    "                'itemsID':items,\n",
    "                'ratings':stars\n",
    "                }\n",
    "    Recommendations_for_Svd=pd.DataFrame(star_dict)\n",
    "    return Recommendations_for_Svd\n",
    "Ph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-49595a7657dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mSvd_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSvd_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mSvd_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSvd_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMake_ready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-49595a7657dc>\u001b[0m in \u001b[0;36mMake_ready\u001b[1;34m(t, d)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mreader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrating_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mSvd_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_from_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRatings_for_Svd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'userID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'itemsID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ratings'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mreader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrating_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sid\\documents\\python\\lib\\site-packages\\surprise\\dataset.py\u001b[0m in \u001b[0;36mload_from_df\u001b[1;34m(cls, df, reader)\u001b[0m\n\u001b[0;32m    162\u001b[0m         \"\"\"\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDatasetAutoFolds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_ratings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sid\\documents\\python\\lib\\site-packages\\surprise\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, ratings_file, reader, df)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             self.raw_ratings = [(uid, iid, float(r), None)\n\u001b[0m\u001b[0;32m    257\u001b[0m                                 \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m                                 self.df.itertuples(index=False)]\n",
      "\u001b[1;32mc:\\users\\sid\\documents\\python\\lib\\site-packages\\surprise\\dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             self.raw_ratings = [(uid, iid, float(r), None)\n\u001b[0m\u001b[0;32m    257\u001b[0m                                 \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m                                 self.df.itertuples(index=False)]\n",
      "\u001b[1;32mc:\\users\\sid\\documents\\python\\lib\\collections\\__init__.py\u001b[0m in \u001b[0;36m_make\u001b[1;34m(cls, iterable)\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnum_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Expected {num_fields} arguments, got {len(result)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Ph = pd.read_csv(\"Pre_use_Predictions.csv\")\n",
    "Ph.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "Ph = np.array(Ph)\n",
    "\n",
    "def Make_ready(t, d):\n",
    "    theta = t\n",
    "    delta = d\n",
    "    Augmented_Ratings = np.array(Ratings)\n",
    "    for i in range(Ratings.shape[0]):\n",
    "        low = np.percentile(Ph[i], theta)\n",
    "        vui = np.sum(Ratings[i])/np.sum(Ratings[i] != 0)\n",
    "        for j in range(Ratings.shape[1]):\n",
    "            if Ph[i][j] <= low:\n",
    "                Augmented_Ratings[i][j] = Ratings[i][j] + vui*delta\n",
    "                \n",
    "    Ratings_for_Svd = Create_Training_set(Augmented_Ratings)\n",
    "    Recommendations_for_Svd = Create_test_Set(Augmented_Ratings)\n",
    "    \n",
    "    reader=Reader(rating_scale=(0,5))\n",
    "    Svd_train = Dataset.load_from_df(Ratings_for_Svd[['userID','itemsID','ratings']],reader)\n",
    "\n",
    "    reader=Reader(rating_scale=(0,5))\n",
    "    Svd_test = Dataset.load_from_df(Recommendations_for_Svd[['userID','itemsID','ratings']],reader)\n",
    "    return Svd_train, Svd_test\n",
    "\n",
    "Svd_train, Svd_test = Make_ready(65, 0.75);    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x24fd1f5b250>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Svd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Svd_train\n",
    "param_grid = {'n_epochs': [40], 'lr_all': [0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "              'reg_all': [0.1, 0.01, 0.001, 0.005]}\n",
    "gs = GridSearchCV(SVDpp, param_grid, measures=['rmse'], n_jobs=-1)\n",
    "\n",
    "fit = gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])\n",
    "fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
